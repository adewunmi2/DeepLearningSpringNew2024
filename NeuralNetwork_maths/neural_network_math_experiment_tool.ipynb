{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network Math Experiment Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# we need this in later phases\n",
    "def activation_ReLu(value):\n",
    "    if value > 0:\n",
    "        return value\n",
    "    else: \n",
    "        return 0\n",
    "    \n",
    "# we need this in later phases\n",
    "def activation_ReLu_partial_derivative(value):\n",
    "    if value > 0:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lock down the randomness\n",
    "np.random.seed(123)\n",
    "\n",
    "def generate_test_data():\n",
    "    result = []\n",
    "\n",
    "    # create 50 numbers\n",
    "    for x in range(100):\n",
    "        n1 = np.random.randint(0, 5)\n",
    "        n2 = np.random.randint(3, 7)\n",
    "        n3 = n1 ** 2 + n2 + np.random.randint(0, 5)\n",
    "        n3 = int(n3)\n",
    "\n",
    "        # add this data row to the list\n",
    "        result.append([n1, n2, n3])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 47.099487762620335\n",
      "Epoch: 2, loss: 25.397147288424918\n",
      "Epoch: 3, loss: 23.018372310372865\n",
      "Epoch: 4, loss: 22.711683294072945\n",
      "Epoch: 5, loss: 22.67116480900928\n",
      "Epoch: 6, loss: 22.665793982431616\n",
      "Epoch: 7, loss: 22.665081753581013\n",
      "Epoch: 8, loss: 22.664987298947644\n",
      "Epoch: 9, loss: 22.664974772430917\n",
      "Epoch: 10, loss: 22.664973111170035\n",
      "Epoch: 11, loss: 22.6649728908544\n",
      "Epoch: 12, loss: 22.664972861636226\n",
      "Epoch: 13, loss: 22.664972857761303\n",
      "Epoch: 14, loss: 22.66497285724743\n",
      "Epoch: 15, loss: 22.664972857179304\n",
      "Epoch: 16, loss: 22.664972857170255\n",
      "Epoch: 17, loss: 22.66497285716902\n",
      "Epoch: 18, loss: 22.66497285716892\n",
      "Epoch: 19, loss: 22.6649728571689\n",
      "Epoch: 20, loss: 22.6649728571689\n",
      "Epoch: 21, loss: 22.6649728571689\n",
      "Epoch: 22, loss: 22.6649728571689\n",
      "Epoch: 23, loss: 22.6649728571689\n",
      "Epoch: 24, loss: 22.6649728571689\n",
      "Epoch: 25, loss: 22.6649728571689\n",
      "Epoch: 26, loss: 22.6649728571689\n",
      "Epoch: 27, loss: 22.6649728571689\n",
      "Epoch: 28, loss: 22.6649728571689\n",
      "Epoch: 29, loss: 22.6649728571689\n",
      "Epoch: 30, loss: 22.6649728571689\n",
      "Epoch: 31, loss: 22.6649728571689\n",
      "Epoch: 32, loss: 22.6649728571689\n",
      "Epoch: 33, loss: 22.6649728571689\n",
      "Epoch: 34, loss: 22.6649728571689\n",
      "Epoch: 35, loss: 22.6649728571689\n",
      "Epoch: 36, loss: 22.6649728571689\n",
      "Epoch: 37, loss: 22.6649728571689\n",
      "Epoch: 38, loss: 22.6649728571689\n",
      "Epoch: 39, loss: 22.6649728571689\n",
      "Epoch: 40, loss: 22.6649728571689\n",
      "Epoch: 41, loss: 22.6649728571689\n",
      "Epoch: 42, loss: 22.6649728571689\n",
      "Epoch: 43, loss: 22.6649728571689\n",
      "Epoch: 44, loss: 22.6649728571689\n",
      "Epoch: 45, loss: 22.6649728571689\n",
      "Epoch: 46, loss: 22.6649728571689\n",
      "Epoch: 47, loss: 22.6649728571689\n",
      "Epoch: 48, loss: 22.6649728571689\n",
      "Epoch: 49, loss: 22.6649728571689\n",
      "Epoch: 50, loss: 22.6649728571689\n",
      "--------------------------\n",
      "ORIGINAL WEIGHTS/BIASES:\n",
      "\n",
      "W1: 1\n",
      "W2: 0.5\n",
      "W3: 1\n",
      "W4: -0.5\n",
      "W5: 1\n",
      "W6: 1\n",
      "B1: 0.5\n",
      "B2: 0\n",
      "B3: 0.5\n",
      "--------------------------\n",
      "FINAL WEIGHTS/BIASES:\n",
      "\n",
      "W1: 2.5742598406171187\n",
      "W2: 0.7594475720019436\n",
      "W3: -9.922388722916562\n",
      "W4: -1.9745198960782555\n",
      "W5: -4.635691921455037\n",
      "W6: -0.4284670480161607\n",
      "B1: -1.2660194157412081\n",
      "B2: -0.19998794074840648\n",
      "B3: 12.334441091141919\n"
     ]
    }
   ],
   "source": [
    "# initialize weights and biases\n",
    "w1 = 1\n",
    "w2 = 0.5\n",
    "w3 = 1\n",
    "w4 = -0.5\n",
    "w5 = 1\n",
    "w6 = 1\n",
    "\n",
    "# and the biases\n",
    "bias1 = 0.5\n",
    "bias2 = 0\n",
    "bias3 = 0.5\n",
    "\n",
    "# save the original weights and biases for comparison in the end\n",
    "original_w1 = w1\n",
    "original_w2 = w2\n",
    "original_w3 = w3\n",
    "original_w4 = w4\n",
    "original_w5 = w5\n",
    "original_w6 = w6\n",
    "original_b1 = bias1\n",
    "original_b2 = bias2\n",
    "original_b3 = bias3\n",
    "\n",
    "# learning rate for gradient descent (optimizer)\n",
    "LR = 0.01\n",
    "epochs =  50\n",
    "\n",
    "# our data\n",
    "# y = x1 ^ 2 + x2 + 1\n",
    "data = [\n",
    "    [1, 0, 2],\n",
    "    [2, 1, 6],\n",
    "    [3, 3, 17]\n",
    "]\n",
    "\n",
    "# replace with generated data (30 rows)\n",
    "data = generate_test_data()\n",
    "\n",
    "loss_points = []\n",
    "\n",
    "# train the neural network\n",
    "for epoch in range(epochs):\n",
    "    for row in data:\n",
    "        # unpack the data into original variables\n",
    "        input1 = row[0]\n",
    "        input2 = row[1]\n",
    "        true_value = row[2]\n",
    "\n",
    "        # FORWARD PASS\n",
    "\n",
    "        # NODE 1 OUTPUT\n",
    "        node_1_output = input1 * w1 + input2 * w3 + bias1\n",
    "        node_1_output = activation_ReLu(node_1_output)\n",
    "        node_1_output\n",
    "\n",
    "        # NODE 2 OUTPUT\n",
    "        node_2_output = input1 * w2 + input2 * w4 + bias2\n",
    "        node_2_output = activation_ReLu(node_2_output)\n",
    "        node_2_output\n",
    "\n",
    "        # NODE 3 OUTPUT \n",
    "        node_3_output = node_1_output * w5 + node_2_output * w6 + bias3\n",
    "        node_3_output = activation_ReLu(node_3_output)\n",
    "        node_3_output\n",
    "\n",
    "        # calculate the loss for this forward pass\n",
    "        predicted_value = node_3_output\n",
    "\n",
    "        # note to self in future\n",
    "        # this will probably crash if the loss value gets too high\n",
    "        # replace with NumPy float64 if needed\n",
    "        loss = (predicted_value - true_value) ** 2\n",
    "\n",
    "        # BACK PROPAGATION - LAST LAYER\n",
    "\n",
    "        # partial derivative of loss function with respect to w5\n",
    "        # use gradient descent to get updated value for w5\n",
    "        deriv_L_w5 = 2 * node_1_output * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        new_w5 = w5 - LR * deriv_L_w5\n",
    "\n",
    "        # partial derivative of loss function with respect to w6\n",
    "        # use gradient descent to get updated value for w6\n",
    "        deriv_L_w6 = 2 * node_2_output * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        new_w6 = w6 - LR * deriv_L_w6\n",
    "\n",
    "        # partial derivative of loss function with respect to bias 3\n",
    "        # use gradient descent to get updated value for bias 3\n",
    "        deriv_L_b3 = 2 * 1 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        new_b3 = bias3 - LR * deriv_L_b3\n",
    "\n",
    "        # FROM THIS POINT FORWARD, WE HAVE TO USE THE CHAIN RULE\n",
    "        # IN ORDER TO ACCESS THE NEXT LAYER AFTER THE FINAL LAYER\n",
    "\n",
    "        # chain rule + partial derivations to solve new value for w1\n",
    "        deriv_L_w1_left = 2 * w5 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_w1_right = activation_ReLu_partial_derivative((input1 * w1) + (input2 * w3) + bias1) * input1\n",
    "        deriv_L_w1 = deriv_L_w1_left * deriv_L_w1_right\n",
    "        new_w1 = w1 - LR * deriv_L_w1\n",
    "\n",
    "        # chain rule + partial derivations to solve new value for w2\n",
    "        deriv_L_w2_left = 2 * w6 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_w2_right = activation_ReLu_partial_derivative((input1 * w2) + (input2 * w4) + bias2) * input1\n",
    "        deriv_L_w2 = deriv_L_w2_left * deriv_L_w2_right\n",
    "        new_w2 = w2 - LR * deriv_L_w2\n",
    "\n",
    "        # chain rule + partial derivations to solve new value for w3\n",
    "        deriv_L_w3_left = 2 * w5 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_w3_right = activation_ReLu_partial_derivative((input1 * w1) + (input2 * w3) + bias1) * input2\n",
    "        deriv_L_w3 = deriv_L_w3_left * deriv_L_w3_right\n",
    "        new_w3 = w3 - LR * deriv_L_w3\n",
    "\n",
    "        # chain rule + partial derivations to solve new value for w4\n",
    "        deriv_L_w4_left = 2 * w6 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_w4_right = activation_ReLu_partial_derivative((input1 * w2) + (input2 * w4) + bias2) * input2\n",
    "        deriv_L_w4 = deriv_L_w4_left * deriv_L_w4_right\n",
    "        new_w4 = w4 - LR * deriv_L_w4\n",
    "\n",
    "        # chain rule + partial derivations to solve new value for bias 1\n",
    "        deriv_L_b1_left = 2 * w5 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_b1_right = activation_ReLu_partial_derivative(input1 * w1 + input2 * w3 + bias1) * 1\n",
    "        deriv_L_b1 = deriv_L_b1_left * deriv_L_b1_right\n",
    "        new_b1 = bias1 - LR * deriv_L_b1\n",
    "\n",
    "        # chain rule + partial derivations to solve new value for bias 2\n",
    "        deriv_L_b2_left = 2 * w6 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_b2_right = activation_ReLu_partial_derivative(input1 * w2 + input2 * w4 + bias2) * 1\n",
    "        deriv_L_b2 = deriv_L_b2_left * deriv_L_b2_right\n",
    "        new_b2 = bias2 - LR * deriv_L_b2\n",
    "\n",
    "        # finally replace old weights with the new ones\n",
    "        w1 = new_w1\n",
    "        w2 = new_w2\n",
    "        w3 = new_w3\n",
    "        w4 = new_w4\n",
    "        w5 = new_w5\n",
    "        w6 = new_w6\n",
    "        bias1 = new_b1\n",
    "        bias2 = new_b2\n",
    "        bias3 = new_b3\n",
    "\n",
    "    \n",
    "\n",
    "    loss_points.append(loss)\n",
    "    print(f\"Epoch: {epoch + 1}, loss: {loss}\")\n",
    "\n",
    "print(\"--------------------------\")\n",
    "print(\"ORIGINAL WEIGHTS/BIASES:\\n\")\n",
    "print(f\"W1: {original_w1}\")\n",
    "print(f\"W2: {original_w2}\")\n",
    "print(f\"W3: {original_w3}\")\n",
    "print(f\"W4: {original_w4}\")\n",
    "print(f\"W5: {original_w5}\")\n",
    "print(f\"W6: {original_w6}\")\n",
    "print(f\"B1: {original_b1}\")\n",
    "print(f\"B2: {original_b2}\")\n",
    "print(f\"B3: {original_b3}\")\n",
    "\n",
    "print(\"--------------------------\")\n",
    "print(\"FINAL WEIGHTS/BIASES:\\n\")\n",
    "print(f\"W1: {w1}\")\n",
    "print(f\"W2: {w2}\")\n",
    "print(f\"W3: {w3}\")\n",
    "print(f\"W4: {w4}\")\n",
    "print(f\"W5: {w5}\")\n",
    "print(f\"W6: {w6}\")\n",
    "print(f\"B1: {bias1}\")\n",
    "print(f\"B2: {bias2}\")\n",
    "print(f\"B3: {bias3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss for the epochs\n",
    "\n",
    "plt.plot(loss_points)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " # prediction is basically just doing the forward \n",
    "# pass again (but only that)\n",
    "def predict(x1, x2):\n",
    "    # NODE 1 OUTPUT\n",
    "    node_1_output = x1 * w1 + x2 * w3 + bias1\n",
    "    node_1_output = activation_ReLu(node_1_output)\n",
    "    node_1_output\n",
    "\n",
    "    # NODE 2 OUTPUT\n",
    "    node_2_output = x1 * w2 + x2 * w4 + bias2\n",
    "    node_2_output = activation_ReLu(node_2_output)\n",
    "    node_2_output\n",
    "\n",
    "    # NODE 3 OUTPUT \n",
    "    node_3_output = node_1_output * w5 + node_2_output * w6 + bias3\n",
    "    node_3_output = activation_ReLu(node_3_output)\n",
    "    node_3_output\n",
    "\n",
    "    return node_3_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0301315055363425"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
